# chatbot
Streamlit web app that lets you chat with a locally running LLaMA3 model via Ollama. Works completely offline and shows conversation history with a built-in reset feature.
## Requirements

- Python 3.13+
- Streamlit
- Requests library
- Ollama installed locally with LLaMA3 model downloaded
## How to Run
-Start Ollama server:
-Run Streamlit app:

streamlit run app.py
